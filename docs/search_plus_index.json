{"./":{"url":"./","title":"前言","keywords":"","body":"编程字典 "},"chapter1/":{"url":"chapter1/","title":"第一章 Linux","keywords":"","body":"第一章 Linux 基础命令 SHELL "},"chapter1/基础命令.html":{"url":"chapter1/基础命令.html","title":"1.1 基础命令","keywords":"","body":"1.1 基础命令 修改主机名 hostnamectl set-hostname test.cn 环境变量 永久生效 vim /etc/profile source /etc/profile 暂时生效 export PATH=$PATH:/usr/local/MATLAB/R2013a/bin 只对当前用户永久生效 vim ~/.bash_profile source ~/.bash_profile 压缩命令 unzip # 解压到当前目录 unzip *.zip # 解压到指定目录，不覆盖 unzip -n *.zip -d /tmp # 解压到指定目录，覆盖 unzip -o *.zip -d /tmp tar # 解压 tar -zxvf *.tar.gz # 压缩 tar -zcvf *.tar.gz # 查看 tar -ztvf *.tar.gz 安装fpm yum -y install ruby rubygems ruby-devel gem sources -a http://mirrors.aliyun.com/rubygems/ gem sources --remove https://rubygems.org/ gem install fpm 分区操作 lvm相关操作1 # 查看pv pvs pvscan pvdisplay # 查看vg vgs vgscan vgdisplay # 查看lvm分区 lvs lvscan lvdisplay 查看磁盘使用 df -h 查看分区使用 fdisk -l lvm分区及挂载 # 查看块设备信息 [root@localhost /]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 2T 0 disk ├─sda1 8:1 0 1M 0 part ├─sda2 8:2 0 512M 0 part /boot ├─sda3 8:3 0 200M 0 part /boot/efi └─sda4 8:4 0 2T 0 part ├─vg_cobbler-lv_root 253:0 0 512G 0 lvm / └─vg_cobbler-lv_swap 253:1 0 16G 0 lvm [SWAP] # 查看vgs的空余大小 [root@localhost /]# vgs VG #PV #LV #SN Attr VSize VFree vg_cobbler 1 3 0 wz--n- 硬盘格式化并挂载 # 查看块设备信息 [root@localhost /]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm [SWAP] sdb 8:16 0 20G 0 disk sdc 8:32 0 20G 0 disk sr0 11:0 1 1024M 0 rom # 可以看到sdb和sdc为未挂载的硬盘 # 格式化sdb并挂载到/data01 # 1. 创建/data01目录 [root@localhost /]# mkdir /data01 # 2. 快速格式化sdb [root@localhost /]# mkfs.ext4 /dev/sdb mke2fs 1.42.9 (28-Dec-2013) /dev/sdb is entire device, not just one partition! Proceed anyway? (y,n) y Filesystem label= OS type: Linux Block size=4096 (log=2) Fragment size=4096 (log=2) Stride=0 blocks, Stripe width=0 blocks 1310720 inodes, 5242880 blocks 262144 blocks (5.00%) reserved for the super user First data block=0 Maximum filesystem blocks=2153775104 160 block groups 32768 blocks per group, 32768 fragments per group 8192 inodes per group Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000 Allocating group tables: done Writing inode tables: done Creating journal (32768 blocks): done Writing superblocks and filesystem accounting information: done # 3. 挂载到/data01 [root@localhost /]# mount /dev/sdb /data01 # 4. 添加开机自动挂载配置 [root@localhost /]# vim /etc/fstab /dev/sdb /data01 ext4 defaults 0 0 # 再次查看块设备信息 [root@localhost /]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm [SWAP] sdb 8:16 0 20G 0 disk /data01 sdc 8:32 0 20G 0 disk sr0 11:0 1 1024M 0 rom # 查看文件系统 [root@localhost /]# df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/centos-root 17G 15G 2.4G 87% / /dev/sda1 1014M 234M 781M 23% /boot /dev/sdb 20G 45M 19G 1% /data01 分区调整 首先确认系统在安装时, 根和/home是否做的是lvm, 如果做了lvm, 那就可以在线进行根分区的扩容3: 1) 先用vgdisplay 查看系统是否有空间空间, 如果还有, 就扩容到根分区. 2) 如果系统没有空闲空间, 就只能从其他lvm分区上缩减出一定的空间, 然后扩容到根分区. 3) 你的/home分区是xfs格式的,缩容之前, 需要先关闭该分区上部署的应用, 把有用数据拷贝到别的分区上, 接着进行缩容, 缩容后重新挂载, 然后再把数据拷贝回来, 重启应用.最后再将/home分区缩容出来的空间在线扩容到根分区上. 使用lvresize调整分区大小后，务必使用xfs_growfs应用分区调整（用词不一定准确，待修改）。 # 压缩home lvm分区30G大小空间，调整后必须对home重新格式化才能使用，不然会报错 lvresize -L -30G /dev/mapper/centos-home # 增加root lvm分区30G大小空间 lvresize -L +30G /dev/mapper/centos-root # 此时使用lvs命令可以看到lvm分区的大小实现了调整，但是df查看文件系统块的大小却没有发现变化 # 调整xfs格式的root lvm分区文件块，xfs_growfs只支持分区增加容量 xfs_growfs /dev/mapper/centos-root # 如果xfs使用resize2f调整分区文件块会报错 resize2fs /dev/mapper/centos-root > resize2fs 1.42.9 (28-Dec-2013) > resize2fs: Bad magic number in super-block while trying to open /dev/mapper/centos-root > Couldn't find valid filesystem superblock. 删除lvm分区 lvremove /dev/centos/home 强制取消挂载 # 查看目录占用 fuser -m /home # 解除占用 fuser -kvm /home # 强制取消挂载 umount -l /home 非LVM分区转化为LVM分区 https://blog.csdn.net/it_is_a_world/article/details/101081754 多个硬盘扩展为一个LVM # 使用整个磁盘创建VG,设置PE大小为64M [root@localhost /]# vgcreate vg_data /dev/vdb /dev/vdc -s 64M # 查看PV [root@localhost /]# pvs # 查看VG [root@localhost /]# vgs # 查看VG详情 [root@localhost /]# vgdisplay vg_data # 使用vg_data创建LV,大小为20T [root@localhost /]# lvcreate -L 20T -n lv_data01 vg_data [root@localhost /]# vgs [root@localhost /]# lvs [root@localhost /]# lvdisplay # 格式化lv_data01 [root@localhost /]# mkfs.ext4 /dev/vg_data/lv_data01 # 创建data01 [root@localhost /]# mkdir /data01 # 挂载lv_data01到/data01 [root@localhost /]# mount /dev/vg_data/lv_data01 /data01 # 添加开机自动挂载配置 [root@localhost /]# vim /etc/fstab > /dev/vg_cobbler/lv_data01 /data01 ext4 defaults 0 0 # 再次查看块设备信息 [root@localhost /]# lsblk # 查看文件系统 [root@localhost /]# df -h su 与 sudo2 su su [-lm] [-c 命令] [username] 参数： -: 单纯使用-如su -，代表使用login-shell的变量文件读取方式来登录系统；不加用户名，则代表切换为root的身份。 -l: 与-类似，但后面需要加欲切换的用户账号。也是login-shell的方式。 -m: -m与-p是一样的，表示使用目前的环境设置，而不读取新用户的配置文件。 -c: 仅进行一次命令，所以-c后面可以加上命令。 sudo 仅需要自己的密码。 sudo [-b] [-u 新用户密码] 参数： -b: 将后续的命令让系统自行执行，而不与目前的shell产生影响。 -u: 后面接欲切换的用户，若无则默认切换root。 可执行sudo的用户与文件/etc/sudoers有关，编辑该文件需用visudo命令。 Login与non-login shell2 login shell: 取得bash时需要完整的登录流程。比如，要由tty1~tty6登录，需要输入用户的账号与密码，此时取得的bash就称为“login shell”。 non-login shell: 取得bash接口的方法不需要重复登录的举动。比如，以X Window登录Linux后，再以X的图形界面启动终端机，此时那个终端接口并没有需要再次输入账号与密码，那个bash的环境就称为non-login shell。在原本的bash环境下再次执行bash这个命令，同样也没有输入账号密码，那第二个bash（子进程）也是non-login shell。 端口 查看端口占用 lsof -i lsof -i:22 netstat -tunlp | grep 8080 netstat –anp | grep 8080 开放端口 # firewall # 开放tcp 端口 firewall-cmd --zone=public --add-port=80/tcp --permanent # 开放udp端口 firewall-cmd --zone=public --add-port=49999/udp --permanent # 刷新加载端口配置 firewall-cmd --reload # 查看开放端口 iptables -L -n # iptables iptables -t filter -I INPUT -p tcp -m tcp --dport 8080 -j ACCEPT 关闭端口 iptables -D INPUT -p tcp --dport 80 -j ACCEPT RPM # 导出目前安装的rpm rpm -qa > list.txt RPM假死 rm -f /var/lib/rpm/__db.00*　#删除rpm数据文件 rpm --rebuilddb　#重新rpm数据文件 查看网卡配置 # 看网关 netstat -rn # 看netmask，dns ifconfig -a ip addr 查看JDK安装 rpm -qa | grep jdk Yum配置 查看源 yum repolist all 配置阿里源 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 配置光盘Yum源 # 挂载光盘 mkdir /media/cdrom mount /dev/cdrom /media/cdrom cd /etc/yum.repos.d # 备份原始源 mkdir backup mv CentOS* backup tar zcvf repos.backup.tar.gz backup mv backup/CentOS-Media.repo . # 修改源地址 vim CentOS-Media.repo > file:///media/cdrom/ > enable=1 # 清除包缓存 yum clean all # 生成缓存 yum makecache LN Linux链接分两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。默认情况下，ln命令产生硬链接。 硬链接相当于对文件进行了备份，防止误删。 软链接相当于Windows的快捷方式。 touch f1 # 创建f1的一个硬链接文件f2 ln f1 f2 # 创建f1的一个软链接文件f3 ln -s f1 f3 时区 # 查看时区 date -R # 修改时区为上海 cp -f /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # 设置时区 timedatectl set-timezone Asia/Shanghai # 设置时间 timedatectl set-time \"YYYY-MM-DD HH:MM:SS\" # 将硬件时钟调整为与本地时钟一致 timedatectl set-local-rtc 1 hwclock --systohc --localtime SSH linux生成密钥 ssh-keygen -t rsa 组操作 # 强行设置某个用户所在组 usermod -g 用户组 用户名 # 把某个用户改为 group(s) usermod -G 用户组 用户名 # 把用户添加进入某个组(s） usermod -a -G 用户组 用户名 # 将用户从组中删除 gpasswd -d 用户名 用户组 Crontab crontab [-u username] [-l|-e|-r] # -u 只有 root 才能进行这个任务 # -l 查看工作内容 crontab -l # -e 编辑工作内容 crontab -e # -r 删除所有的工作内容 crontab -r # 启动服务 systemctl start crond.service # 关闭服务 systemctl stop crond.service # 重启服务 systemctl restart crond.service # 重新载入配置 systemctl reload crond.service # 查看状态 systemctl status crond.service # 查看日志 tail -1000f /var/log/cron 将crontab文件放在/etc/cron.d下，然后执行systemctl restart crond.service重启crontab服务。 crontab 不执行的原因 未重启crond服务/未重载（reload）crond配置 文件换行不是unix crontab文件末尾没有空行 系统版本 cat /etc/redhat-release uname -a # centos 统计文件/目录 # 1、 统计当前文件夹下文件的个数 ls -l |grep \"^-\"|wc -l # 2、 统计当前文件夹下目录的个数 ls -l |grep \"^d\"|wc -l # 3、统计当前文件夹下文件的个数，包括子文件夹里的 ls -lR|grep \"^-\"|wc -l # 4、统计文件夹下目录的个数，包括子文件夹里的 ls -lR|grep \"^d\"|wc -l grep \"^-\" # 这里将长列表输出信息过滤一部分，只保留一般文件，如果只保留目录就是 ^d wc -l Jfrog 的Artifactory 命令的使用 预先设置 jfrog rt config --user= --password= --url=https://xxx.xx.xx/artifactory --interactive=false api与url 如果不预先设置，需要在命令后面添加--url=和--apikey= 目录的下载 jfrog.exe rt dl --url=“https://xxx.xxx.xx/artifactory” --threads=1 --split-count=0 目录上传 jfrog rt u --flat=false # 上传后，在服务器上的路径将是 + # 如果想上传目录层次比较少，可以先在本地进入需要上传的目录下，在执行jfrog命令 目录删除 jfrog rt del --quiet=true 查看MD5 md5sum 文件名 SYSLOG Mar 20 12:28:48 TAC 1. centos7下修改分区大小（LVM） ↩ 2. 鸟哥的Linux私房菜·基础学习篇（第三版），P428-433 ↩ 3. Linux下对lvm逻辑卷分区大小的调整（针对xfs和ext4不同文件系统） ↩ "},"chapter1/SHELL.html":{"url":"chapter1/SHELL.html","title":"1.2 SHELL","keywords":"","body":"1.2 SHELL 判断是否为空 if [ -n \"$APP_ID\" ]; then echo \"is not empty\" fi if [ -z \"$APP_ID\" ]; then echo \"is empty\" fi 获取参数 #!/bin/bash echo $1 $2 # 获取当前进程id echo $! # 当前脚本的文件名 echo $0 数组循环 for type in ${TYPES[@]}; do TYPES_STR=\"$TYPES_STR $type\" done # 获取数组元素 echo \"数组的元素为: ${my_array[*]}\" echo \"数组的元素为: ${my_array[@]}\" # 获取数组长度 echo \"数组元素个数为: ${#my_array[*]}\" echo \"数组元素个数为: ${#my_array[@]}\" 基本循环 for ((i = 0; i 文件判断 # 文件不存在 if [ ! -f \"$file\" ]; then touch \"$file\" fi # 文件夹不存在 if [ ! -d \"$folder\"]; then mkdir \"$folder\" fi 数字大小判断 if [ $num1 -gt $num2 ] ; then echo \"$num1 > $num2\" else echo \"$num1 获取函数返回值 #!/bin/bash funWithReturn(){ echo \"这个函数会对输入的两个数字进行相加运算...\" echo \"输入第一个数字: \" read aNum echo \"输入第二个数字: \" read anotherNum echo \"两个数字分别为 $aNum 和 $anotherNum !\" return $(($aNum+$anotherNum)) } funWithReturn echo \"输入的两个数字之和为 $? !\" 字符串匹配 ==比较 使用bash检查字符串是否以某些字符开头可以使用==比较 [[ $str == h* ]] 示例 str=\"hello\" if [[ $str == h* ]]; then echo 'yes' fi 有两个地方需要注意： h*不需要使用引号括起来，使用引号括起来是直接做相等比较 比较语句使用双中括号括起来，而不是使用单中括号 =~正则比较 如果使用Bash的正则 str=\"hello\" if [[ \"$str\" =~ ^he.* ]]; then echo \"yes\" fi 使用正则匹配字符串的开头字符需要注意： he*：不要使用he*，这里的*号表示e字符0到多个，即h，以及heeee都是测试通过的 he.*：这里只允许包含he的字符串通过测试 ^he.*：这个表示是以he开头的字符串通过检测 命令找不到（command not found） export PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin source /etc/profile # 或者 /bin/vi /etc/profile 文件内容删除（sed） FILE=\"/usr/local/test.path\" CONTENT=\"/usr/local/test.txt\" # 将\"/\"替换为\"\\/\" CONTENT_REG=${CONTENT//\\//\\\\/} # 适用sed删除 sed -i ${CONTENT_REG}/d ${FILE} $ 变量含义 linux中shell变量$#,$@,$0,$1,$2的含义解释: $$ # Shell本身的PID（ProcessID） $! # Shell最后运行的后台Process的PID $? # 最后运行的命令的结束代码（返回值） $- # 使用Set命令设定的Flag一览 $* # 所有参数列表。如\"$*\"用「\"」括起来的情况、以\"$1 $2 … $n\"的形式输出所有参数。 $@ # 所有参数列表。如\"$@\"用「\"」括起来的情况、以\"$1\" \"$2\" … \"$n\" 的形式输出所有参数。 $# # 添加到Shell的参数个数 $0 # Shell本身的文件名 $1～$n # 添加到Shell的各参数值 "},"chapter2/":{"url":"chapter2/","title":"第二章 语言","keywords":"","body":"第二章 语言 "},"chapter2/Python.html":{"url":"chapter2/Python.html","title":"2.1 Python","keywords":"","body":"2.1 Python 离线安装库 # 1. 查看安装的包 pip list # 2. 生成依赖列表 pip freeze >requirements.txt # 3. 下载依赖文件的包到本地 pip download -d .\\packages -r .\\requirements.txt --trusted-host mirrors.aliyun.com # 4. 离线安装 pip install --no-index --find-links .\\packages -r .\\requirements.txt pip install numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl # 5. 安装 tar.gz tar -zxvf xxx.tar.gz cd xxx python setup.py install str bytes互转 # bytes object b = b\"example\" # str object s = \"example\" # str to bytes bytes(s, encoding = \"utf8\") # bytes to str str(b, encoding = \"utf-8\") # an alternative method # str to bytes str.encode(s) # bytes to str bytes.decode(b) Conda 强制卸载 conda remove --force name 离线安装 conda install --use-local pytorch-1.0.0-py2.7_cuda9.0.176_cudnn7.4.1_1.tar.bz2 "},"chapter2/Java.html":{"url":"chapter2/Java.html","title":"2.2 Java","keywords":"","body":"2.2 Java [TOC] 基础 获取文件最后的修改时间 import java.io.File; import java.util.Date; public class Main { public static void main(String[] args) { File file = new File(\"Main.java\"); Long lastModified = file.lastModified(); Date date = new Date(lastModified); System.out.println(date); } } JAR无法读取配置文件 public static String readFileByStream(String fileName){ try { StringBuilder stringBuffer = new StringBuilder(); InputStream stream = FilesUtils.class.getClassLoader().getResourceAsStream(fileName); if (stream == null) { return null; } BufferedReader br = new BufferedReader(new InputStreamReader(stream, StandardCharsets.UTF_8)); String line; while ((line = br.readLine()) != null) { stringBuffer.append(line); } return stringBuffer.toString(); } catch (Exception e) { e.printStackTrace(); } return null; } 读取JSON文件中的unicode 使用JSONObject转化一遍。 IDEA 开启控制台颜色 # Edit Configurations，点击，找到VM options添加 -Dspring.output.ansi.enabled=ALWAYS 添加启动命令 Edit Configurations->Env Vars: \"spring.profiles.active=dev\" Spring Boot 打包 为方便程序的安装与运行，将JAR与运行脚本打包为RPM包。 开启SSL1 生成证书 keytool -genkey -keyalg RSA -keysize 2048 -validity 3650 -keystore application.keystore -storepass PASS@2019 -storetype PKCS12 添加配置到配置文件application.properties server.port=443 server.http.port=80 ######## SSL ######## server.ssl.key-store=classpath:application.keystore server.ssl.key-store-password=PASS@2019 server.ssl.key-store-type=PKCS12 在启动类*Application.java配置连接器，同时启用HTTP和HTTPS // 兼容HTTP 和 HTTPS @Bean public ServletWebServerFactory servletContainer(){ TomcatServletWebServerFactory tomcat = new TomcatServletWebServerFactory(); tomcat.addAdditionalTomcatConnectors(createHTTPConnector()); return tomcat; } // HTTP自动跳转到HTTPS @Bean public TomcatServletWebServerFactory servletContainer() { TomcatServletWebServerFactory tomcat = new TomcatServletWebServerFactory() { @Override protected void postProcessContext(Context context) { SecurityConstraint securityConstraint = new SecurityConstraint(); securityConstraint.setUserConstraint(\"CONFIDENTIAL\"); SecurityCollection collection = new SecurityCollection(); collection.addPattern(\"/*\"); securityConstraint.addCollection(collection); context.addConstraint(securityConstraint); } }; tomcat.addAdditionalTomcatConnectors(httpConnector()); return tomcat; } private Connector createHTTPConnector() { Connector connector = new Connector(\"org.apache.coyote.http11.Http11NioProtocol\"); connector.setScheme(\"http\"); connector.setSecure(false); connector.setPort(httpPort); connector.setRedirectPort(httpsPort); return connector; } 启用Actuator org.springframework.boot spring-boot-starter-actuator management.endpoints.web.exposure.include=env,beans,health,autoconfig management.server.port=8110 management.server.servlet.context-path=/ management.server.ssl.enabled=false management.endpoint.health.show-details=always 查看状态 GET: http://{host}:{port}/actuator { \"_links\": { \"self\": { \"href\": \"http://localhost:8110/actuator\", \"templated\": false }, \"beans\": { \"href\": \"http://localhost:8110/actuator/beans\", \"templated\": false }, \"health-component-instance\": { \"href\": \"http://localhost:8110/actuator/health/{component}/{instance}\", \"templated\": true }, \"health-component\": { \"href\": \"http://localhost:8110/actuator/health/{component}\", \"templated\": true }, \"health\": { \"href\": \"http://localhost:8110/actuator/health\", \"templated\": false }, \"env\": { \"href\": \"http://localhost:8110/actuator/env\", \"templated\": false }, \"env-toMatch\": { \"href\": \"http://localhost:8110/actuator/env/{toMatch}\", \"templated\": true } } } 创建非Web项目 Logback(Slf4j)配置文件 在Spring Boot中默认使用Logback作为日志插件，Logback的默认配置文件为logback-spring.xml，文件内容示例如下。 logback ERROR --> ${log.pattern} %d{HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36} - %msg%n--> ${log.path}/${app.name}.%d{yyyy-MM-dd}.log ${log.pattern} %d{HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36} - %msg%n--> ${log.path}/${app.name}.%d{yyyy-MM-dd}.%i.log 30 128MB 1024MB ${log.pattern} %d{HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36} - %msg%n--> 异常 The server sockets created using the LocalRMIServerSocketFactory 日志错误 AM sun.rmi.transport.tcp.TCPTransport$AcceptLoop executeAcceptLoop WARNING: RMI TCP Accept-0: accept loop for ServerSocket[addr=0.0.0.0/0.0.0.0,localport=32658]s java.io.IOException: The server sockets created using the LocalRMIServerSocketFactory only aconnections from clients running on the host where the RMI remote objects have been exported. at sun.management.jmxremote.LocalRMIServerSocketFactory$1.accept(LocalRMIServerSockety.java:114) at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.executeAcceptLoop(TCPTransport.java: at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.run(TCPTransport.java:372) at java.lang.Thread.run(Thread.java:745) 解决方法 1) fix etc hosts or 2) disable local host checks. Disabling local host checking can be done in two ways: a) system-wide: uncomment the line # com.sun.management.jmxremote.local.only=false in jre/lib/management/management.properties b) process based: pass -Dcom.sun.management.jmxremote.local.only=false on the java command line (attachee side) Maven基础 # 不执行测试用例，也不编译测试用例类 mvn package -Dmaven.test.skip=true # 不执行测试用例，但编译测试用例类生成相应的class文件至target/test-classes下 mvn package -DskipTests # mvn源更新后，刷新本地缓存 mvn clean package -U 1. springboot 2.X 配置SSL证书 ↩ "},"chapter3/":{"url":"chapter3/","title":"第三章 数据库","keywords":"","body":"第三章 数据库 "},"chapter3/MySQL.html":{"url":"chapter3/MySQL.html","title":"3.1 MySQL","keywords":"","body":"3.1 MySQL [TOC] 安装MySQL 卸载mariadb rpm -qa | grep mariadb rpm -e --nodeps mariadb-libs 在线安装 wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm sudo rpm -ivh mysql-community-release-el7-5.noarch.rpm sudo yum -y install mysql-server rpm安装 rpm -ivh mysql-community-common rpm -ivh mysql-community-lib rpm -ivh mysql-community-client rpm -ivh mysql-community-server service mysqld start 查看安装默认密码 cat /var/log/mysqld.log |grep password 修改密码 mysql > set global validate_password_policy=0; mysql > set global validate_password_length=1; mysql > ALTER USER USER() IDENTIFIED BY '123456'; mysql > use mysql; mysql > update user set password=password('123456') where user='root'; mysql > select host,user, password from user; mysql > GRANT ALL PRIVILEGES ON *.* TO root@\"%\" IDENTIFIED BY \"root\"; mysql > flush privileges; mysql > exit; service mysqld restart windows mysql 5.7 修改密码 mysql > use mysql; mysql > update user set authentication_string=password('新密码') where user='root' and Host='localhost'; mysql > flush privileges; mysql > exit; 允许远程 mysql > use mysql; mysql > GRANT ALL PRIVILEGES ON *.* TO root@\"%\" IDENTIFIED BY \"新密码\"; mysql > flush privileges; mysql > exit; service mysqld restart 开放端口 firewall-cmd --zone=public --add-port=3306/tcp --permanent firewall-cmd --reload iptables -L -n 查看连接占用 show processlist; show full processlist; show status; ON DUPLICATE KEY UPDATE 判断记录是否存在,不存在则插入存在则更新的场景. 举个例子，字段a被定义为UNIQUE，并且原数据库表table中已存在记录(2,2,9)和(3,2,1)，如果插入记录的a值与原有记录重复，则更新原有记录，否则插入新行： INSERT INTO TABLE (a,b,c) VALUES (1,2,3), (2,5,7), (3,3,6), (4,8,2) ON DUPLICATE KEY UPDATE b=VALUES(b); 以上SQL语句的执行，发现(2,5,7)中的a与原有记录(2,2,9)发生唯一值冲突，则执行ON DUPLICATE KEY UPDATE，将原有记录(2,2,9)更新成(2,5,9)，将(3,2,1)更新成(3,3,1)，插入新记录(1,2,3)和(4,8,2) 注意：ON DUPLICATE KEY UPDATE只是MySQL的特有语法，并不是SQL标准语法！ 删除字段为NULL DELETE FROM table_name WHERE type is NULL; 查看连接 show full processlist; 查看状态 show status; "},"chapter3/Redis.html":{"url":"chapter3/Redis.html","title":"3.2 Redis","keywords":"","body":"3.2 Redis 安装Redis # 下载 wget http://download.redis.io/releases/redis-5.0.5.tar.gz # 解压 tar xzf redis-5.0.5.tar.gz # 编译 cd redis-5.0.5 make # 将编译文件放于/usr/local/redis下 mkdir /usr/local/redis cp src/redis-cli /usr/local/redis cp src/redis-server /usr/local/redis cp redis.conf /usr/local/redis 允许远程 编辑配置文件vim /usr/local/redis/redis.conf，找到相应行修改： # bind 127.0.0.1 protected-mode no # 取消守护启动，用于开机自启 daemonize no 自启配置 添加服务脚本vim /etc/systemd/system/redis.service： [Unit] Description=Redis Server Manager After=syslog.target After=network.target [Service] # Type=simple PIDFile=/var/run/redis_6379.pid ExecStart=/usr/local/redis/redis-server /usr/local/redis/redis.conf ExecStop=/usr/local/redis/redis-cli shutdown Restart=always [Install] WantedBy=multi-user.target 添加服务，开机启动： systemctl daemon-reload systemctl start redis.service systemctl enable redis.service 添加redis-cli软链接： ln -s /usr/local/redis/redis-cli /usr/bin/redis-cli 开放端口 firewall-cmd --zone=public --add-port=6379/tcp --permanent firewall-cmd --reload iptables -L -n 基本操作 # 查看所有key keys * # 获取所有配置 config get * 错误 使用spring boot连接redis发现redis中数据无故无规律清空 a. 修改redis service文件vim /etc/systemd/system/redis.service b. 修改redis配置文件，增加logfile路径 c. 修改系统时区 然后就未出现当前问题，但是并未确定问题的原因。 "},"chapter4/":{"url":"chapter4/","title":"第四章 工具","keywords":"","body":"第四章 工具 "},"chapter4/Git.html":{"url":"chapter4/Git.html","title":"4.1 Git","keywords":"","body":"4.1 Git [TOC] 安装Git 下载 wget https://www.kernel.org/pub/software/scm/git/git-2.11.1.tar.gz 安装依赖 yum groupinstall \"Development Tools\" yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel perl-CPAN perl-devel perl-ExtUtils-Embed 解压安装 tar -zvxf git-2.11.1.tar.gz cd git-2.11.1 # 指向ssl安装位置 ./configure --with-openssl=/usr/local/openssl make install rpm -e git --nodeps ln -s /usr/local/bin/git /usr/bin/git git version 修改默认编辑器 以sublime为例，需将sublime_text.exe的路径添加到环境变量中。 git config --global core.editor sublime_text.exe 修改已commit的注释信息 git commit --amend 查看用户名和邮箱地址 git config user.name git config user.email 修改用户名和邮箱地址 git config --global user.name \"username\" git config --global user.email \"email\" 文件换行格式 # 提交时转换为LF，检出时不转换 git config --global core.autocrlf input # 拒绝提交包含混合换行符的文件 git config --global core.safecrlf true 查看所有的提交记录 git log 查看最新的commit git show 查看指定commit hashID的所有修改 git show commitId 查看某次commit中具体某个文件的修改 git show commitId fileName 回到与远程仓库一致处 git fetch --all git reset --hard origin/develop git pull 标签 # 新建一个标签 git tag # 可以指定标签信息 git tag -a v0.1 -m \"version 0.1 released\" # 查看所有标签 git tag # 推送标签 git push origin v1.5 # 删除标签 git tag -d v1.4-lw # 删除远程标签 git push origin :refs/tags/v1.4-lw # 检出标签 git checkout 2.0.0 修改 comment git commit --amend 清除本地的新增文件（未add） git clean -df 常见问题 fatal: write error: Broken pipe git config http.postBuffer 104857600 中文乱码处理 # 注释：该命令表示提交命令的时候使用utf-8编码集提交 git config --global i18n.commitencoding utf-8 # 注释：该命令表示日志输出时使用utf-8编码集显示 git config --global i18n.logoutputencoding utf-8 # 注释：设置LESS字符集为utf-8 export LESSCHARSET=utf-8 Git LFS 介绍 Git 大文件存储（Large File Storage，简称LFS）目的是更好地把大型二进制文件，比如音频文件、数据集、图像和视频等集成到 Git 的工作流中。我们知道，Git 存储二进制效率不高，因为它会压缩并存储二进制文件的所有完整版本，随着版本的不断增长以及二进制文件越来越多，这种存储方案并不是最优方案。而 LFS 处理大型二进制文件的方式是用文本指针替换它们，这些文本指针实际上是包含二进制文件信息的文本文件。文本指针存储在 Git 中，而大文件本身通过HTTPS托管在Git LFS服务器上。 安装 git lfs install Updated git hooks. Git LFS initialized. LFS追踪文件 git lfs track \"*.zip\" git lfs track \"Anaconda3-4.4.0-Linux-x86_64.sh\" 执行命令后，将会在项目中生成.gitattributes文件，该文件保存文件的追踪记录，需要将该文件推送到远程仓库当中。 查看追踪规则 git lfs track Listing tracked patterns *.iso (.gitattributes) grafana-6.4.3-1.x86_64.rpm (.gitattributes) Listing excluded patterns 提交&推送 与git基本操作一致，使用”git add“，”git commit“，”git push“命令。 # 添加 git add Anaconda3-4.4.0-Linux-x86_64.sh # 提交 git commit -m \"添加大文件 Anaconda3-4.4.0-Linux-x86_64.sh\" # 推送 git push 查看追踪列表 git lfs ls-files 194faa7784 * grafana-6.4.3-1.x86_64.rpm 克隆&拉取 与git基本操作一致，使用git clone,git pull命令。 # 克隆 git clone git@gitlab.example.com:group/project.git # 拉取 git lfs fetch origin master 1. https://docs.gitlab.com/ee/administration/lfs/manage_large_binaries_with_git_lfs.html ↩ "},"chapter5/":{"url":"chapter5/","title":"第五章 大数据","keywords":"","body":"第五章 大数据组件 "},"chapter5/Kafka.html":{"url":"chapter5/Kafka.html","title":"5.1 Kafka","keywords":"","body":"5.1 Kafka [TOC] 启动Zookeeper /usr/local/kafka/bin/zookeeper-server-start.sh /usr/local/kafka/config/zookeeper.properties & 启动Kafka Broker /usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties & 查看kafka topics /usr/local/kafka/bin/kafka-topics.sh --list --zookeeper localhost:2181 新建topic /usr/local/kafka/bin/kafka-topics.sh --create --replication-factor 1 --partitions 1 --zookeeper localhost:2181 --topic ${topic} 删除kafka topics /usr/local/kafka/bin/kafka-topics.sh --delete --zookeeper localhost:2181 --topic ${topic} 产生消息 /usr/local/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic ${topic} 接收消息 /usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic ${topic} 查看topic信息 /usr/local/kafka/bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic ${topic} 重置组消费位置 bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group test-group --reset-offsets --all-topics --to-earliest --execute bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group test-group --reset-offsets --topic ${topic} --to-earliest --execute 无法启动 "},"chapter5/ES.html":{"url":"chapter5/ES.html","title":"5.2 ES","keywords":"","body":"5.2 ES 查看mapping curl -XGET '127.0.0.1:9200/noah_app_access_20200101/_mapping/?pretty=true' 统计某个字段的数目 http://host:9200/_sql?sql=SELECT count(distinct(resource_id)) as num FROM index_* 查看索引数据 POST http://host:9200/index_*/_search?pretty Body { \"size\":1000 } 删除索引 curl -XDELETE '127.0.0.1:9200/index_*' "},"chapter5/HDFS.html":{"url":"chapter5/HDFS.html","title":"5.3 HDFS","keywords":"","body":"5.3 HDFS [TOC] 退出安全模式 bin/hadoop dfsadmin -safemode leave 进入安全模式 bin/hadoop dfsadmin -safemode enter 恢复edits不一致 bin/hadoop namenode -recover 在HDFS中，提供了fsck命令，用于检查HDFS上文件和目录的健康状态、获取文件的block信息和位置信息等。 fsck命令必须由HDFS超级用户来执行，普通用户无权限。 查看文件中损坏的块（-list-corruptfileblocks） [root@master sbin]$ hdfs fsck / -list-corruptfileblocks 将损坏的文件移动至/lost+found目录（-move） [root@master sbin]$ hdfs fsck / -move 删除损坏的文件（-delete） [root@master sbin]$ hdfs fsck / -delete 检查并列出所有文件状态（-files） [root@master sbin]$ hdfs fsck / -files 查看dfs块的报告 [root@master sbin]$ hdfs dfsadmin -report 查看目录 [root@master sbin]$ hdfs -ls / HDFS datanode无法启动 Directory /data05/block is in an inconsistent state: cluster Id is incompatible with others. 停止namenode 删除data的current内容 rm -rf /data*/block/current/* 格式化 ./hdfs namenode -format 重启 "},"chapter5/Hive.html":{"url":"chapter5/Hive.html","title":"5.4 Hive","keywords":"","body":"5.4 Hive "},"chapter5/Flume.html":{"url":"chapter5/Flume.html","title":"5.5 Flume","keywords":"","body":"5.5 Flume "},"END.html":{"url":"END.html","title":"结语","keywords":"","body":"结语 "}}